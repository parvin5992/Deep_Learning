{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82706200-d262-42f6-ba27-1d7d5bde3bbd",
   "metadata": {},
   "source": [
    "### کتابخانه قدرتمند pytorch این امکان را به شما می دهد که در حین کار تغییراتی را اعمال کنید(مدل خود را تغییر دهید)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59adc436-ddb9-4984-95f0-959b0d8baaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/78/18/7a2e56e2dc45a433dea9e1bf46a65e234294c9c470ccb4d4b53025f57b23/torch-2.5.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.5.0-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\tara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.8.0)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/8b/4e/bf7a4ccc11ded738efd0bda39296c7cee3617e800f890f919de5c0fe00c8/networkx-3.4.1-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/1d/a0/6aaea0c2fbea2f89bfd5db25fb1e3481896a423002ebe4e55288907a97a3/fsspec-2024.9.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tara\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.5.0-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "   ---------------------------------------- 0.0/179.3 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 20.5/179.3 kB 330.3 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 61.4/179.3 kB 656.4 kB/s eta 0:00:01\n",
      "   ------------------------------- ------- 143.4/179.3 kB 54.3 kB/s eta 0:00:01\n",
      "   --------------------------------------- 179.3/179.3 kB 68.0 kB/s eta 0:00:00\n",
      "Downloading networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.7 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.4/1.7 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 399.4/536.2 kB 24.3 MB/s eta 0:00:01\n",
      "   -------------------------------------  532.5/536.2 kB 630.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 536.2/536.2 kB 623.2 kB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, torch\n",
      "Successfully installed fsspec-2024.9.0 mpmath-1.3.0 networkx-3.4.1 sympy-1.13.1 torch-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18e46bd-adfb-43d2-a2a0-9fe68134178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce470b49-40e7-4c27-88c8-ca74bc73d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70268457-872a-4062-ac64-f0b59004b637",
   "metadata": {},
   "source": [
    "torch.folat32\n",
    "torch.folat64\n",
    "torch.folat16\n",
    "torch.int8\n",
    "torch.int32\n",
    "torch.int16\n",
    "torch.int64\n",
    "torch.unit64\n",
    "torch.bool\n",
    "torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05c2611-3287-437b-8279-8873529af545",
   "metadata": {},
   "source": [
    "How can I creat a scalar inside PyTorch as a Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a3c01b-0644-4c3f-a724-788223629aed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# scalar_data1= torch.tensor(12)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# scalar_data1= torch.tensor(56.7)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# scalar_data1= torch.tensor(True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m scalar_data2\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m12\u001b[39m,dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m----> 5\u001b[0m scalar_data1\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(scalar_data1)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(scalar_data1\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# scalar_data1= torch.tensor(12)\n",
    "# scalar_data1= torch.tensor(56.7)\n",
    "# scalar_data1= torch.tensor(True)\n",
    "scalar_data2= torch.tensor(12,dtype = torch.float64)\n",
    "scalar_data1= torch.tensor(12,dtype = torch.float64,device=\"cuda\")\n",
    "\n",
    "print(scalar_data1)\n",
    "print(scalar_data1.dtype)\n",
    "print(scalar_data1.shape)\n",
    "# or\n",
    "print(scalar_data1.size())\n",
    "print(scalar_data1.device)\n",
    "print(100*\"=\")\n",
    "print(scalar_data2)\n",
    "print(scalar_data2.dtype)\n",
    "print(scalar_data2.shape)\n",
    "# or\n",
    "print(scalar_data2.size())\n",
    "print(scalar_data2.device)\n",
    "print(100*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144f926-91f5-4407-b0f5-5e35207fa008",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data1=torch.tensor([21.3,54,5,5,4,343,234])\n",
    "print(vector_data1)\n",
    "print(vector_data1.dtype)\n",
    "print(vector_data1.shape)\n",
    "# or\n",
    "print(vector_data1.size())\n",
    "print(vector_data1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0341c5b-33f7-465a-81ba-b4c492a8b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data1=torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [10,11,12]\n",
    "])\n",
    "print(mat_data1)\n",
    "print(mat_data1.dtype)\n",
    "print(mat_data1.shape)\n",
    "# or\n",
    "print(mat_data1.size())\n",
    "print(mat_data1.device)\n",
    "print(100*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a390b-c661-4c54-90e8-9547cc47c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_data1=torch.tensor([\n",
    "    [[1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]],\n",
    "    [[1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],]\n",
    "])\n",
    "print(td_data1)\n",
    "print(td_data1.dtype)\n",
    "print(td_data1.shape)\n",
    "# or\n",
    "print(td_data1.size())\n",
    "print(td_data1.device)\n",
    "print(100*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06995d9d-570a-4a1c-9a82-be7e6b14be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
